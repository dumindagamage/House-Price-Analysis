{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# House Price Analytics\n",
        "\n",
        "## 02 Data Tranformation and Loading\n",
        "\n",
        "**Project:** Code Institute â€“ Capstone Project\n",
        "\n",
        "---\n",
        "### **Objectives**\n",
        "- Load the cleaned house dataset\n",
        "- Set datatypes\n",
        "- Encode categorical variables for analysis.\n",
        "- Introduce required features for analaysis\n",
        "- Prepare the dataset for analysis and prediction\n",
        "\n",
        "### **Inputs**\n",
        "- `data/processed/cleaned_house_data.csv`\n",
        "\n",
        "### **Outputs**\n",
        "- `data/processed/final_house_data.csv`\n",
        "        \n",
        "### **Additional Comments**\n",
        "Confirm the cleaned_house_data.csv is exisit under outputs/datasets. Run this notebook top-down."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9uWZXH9LwoQg"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Setup the file and Load the Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Ignore warning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import warnings \n",
        "# Ignore future warnings\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Import nesessary libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Set the home directory. Need to change the working directory from its current folder to its parent folder. Access the current directory with os.getcwd()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Working directory: c:\\MyStuff\\CodeInstitute\\Projects\\ci-project-02\\Home-Value-Analysis\\notebooks\n"
          ]
        }
      ],
      "source": [
        "PROJECT_DIR = os.path.join(os.getcwd()) # Define the project root directory\n",
        "os.chdir(PROJECT_DIR) # Change the current working directory\n",
        "print(\"Working directory:\", os.getcwd()) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Load the data from the original data set reside within data directory under data/processed/ directory. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset loaded successfully.\n",
            "Original dataset shape: (21596, 21)\n"
          ]
        }
      ],
      "source": [
        "# LOAD DATASET\n",
        "try:\n",
        "    # Data directory paths\n",
        "    data_path = os.path.join(\"..\",\"data\", \"processed\")\n",
        "    # Extract the original dataset\n",
        "    df = pd.read_csv(os.path.join(data_path, \"cleaned_house_data.csv\"))\n",
        "    print(\"Dataset loaded successfully.\")\n",
        "except Exception as e:\n",
        "    print(e)\n",
        "    print(\"Error loading the dataset.\")\n",
        "    df = pd.DataFrame()  # Create an empty DataFrame if loading fails\n",
        "\n",
        "print(f\"Original dataset shape: {df.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Feature Engineering\n",
        "\n",
        "1.  **Date Parsing:** The raw `date` string is not usable for seasonality analysis. We need to extract Year, Month, and Quarter.\n",
        "2.  **Age Calculation:** Raw `yr_built` is hard to interpret. `house_age` gives immediate context.\n",
        "3.  **Renovation Logic:** `yr_renovated` contains '0' for non-renovated homes. We need a binary flag `is_renovated` to compare groups.\n",
        "4.  **Log Transformation:** As identified in Notebook 01, `price` is highly skewed. `price_log` normalizes this for future Machine Learning models.\n",
        "5.  **Price per sqft:** Analyzing total price alone is biased by size. price_per_sqft provides a standardized metric, allowing us to compare the true \"value density\" of homes across different neighborhoods independent of their square footage. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "        date  sale_month  house_age  is_renovated  price_log  price_per_sqft  \\\n",
            "0 2014-10-13          10         59             0  12.309987      188.050847   \n",
            "1 2014-12-09          12         63             1  13.195616      209.338521   \n",
            "2 2015-02-25           2         82             0  12.100718      233.766234   \n",
            "3 2014-12-09          12         49             0  13.311331      308.163265   \n",
            "4 2015-02-18           2         28             0  13.142168      303.571429   \n",
            "\n",
            "   age_group  \n",
            "0  1950-1990  \n",
            "1  1950-1990  \n",
            "2   Pre-1950  \n",
            "3  1950-1990  \n",
            "4  1950-1990  \n"
          ]
        }
      ],
      "source": [
        "# 1. Date Transformations\n",
        "df['date'] = pd.to_datetime(df['date'])\n",
        "df['sale_year'] = df['date'].dt.year\n",
        "df['sale_month'] = df['date'].dt.month\n",
        "df['sale_quarter'] = df['date'].dt.quarter\n",
        "\n",
        "# Map month numbers to names for clearer visuals later\n",
        "month_map = {1:'Jan', 2:'Feb', 3:'Mar', 4:'Apr', 5:'May', 6:'Jun',\n",
        "             7:'Jul', 8:'Aug', 9:'Sep', 10:'Oct', 11:'Nov', 12:'Dec'}\n",
        "df['sale_month_name'] = df['sale_month'].map(month_map)\n",
        "\n",
        "# 2. Age & Renovation Features\n",
        "# Age at time of sale\n",
        "df['house_age'] = df['sale_year'] - df['yr_built']\n",
        "\n",
        "# Binary Renovation Flag (1 = Renovated, 0 = Not)\n",
        "df['is_renovated'] = df['yr_renovated'].apply(lambda x: 1 if x > 0 else 0)\n",
        "\n",
        "# \"Effective Age\": Years since the last major update (Construction or Renovation)\n",
        "df['years_since_update'] = df.apply(lambda row: row['sale_year'] - max(row['yr_built'], row['yr_renovated']), axis=1)\n",
        "\n",
        "# 3. Price Transformations (Handling Skewness)\n",
        "# Log transformation using log1p (log(1+x)) to handle any edge cases, though price > 0\n",
        "df['price_log'] = np.log1p(df['price'])\n",
        "\n",
        "\n",
        "# 4. Diagnostic Helper: Age Groups\n",
        "# This is needed for the Seller Diagnostic Analysis in Notebook 04\n",
        "bins = [1900, 1950, 1990, 2016]\n",
        "labels = ['Pre-1950', '1950-1990', 'Post-1990']\n",
        "df['age_group'] = pd.cut(df['yr_built'], bins=bins, labels=labels, right=False)\n",
        "\n",
        "# 5. Price per Square Foot\n",
        "# Calculated as price divided by living area in square feet\n",
        "df['price_per_sqft'] = df['price'] / df['sqft_living']\n",
        "\n",
        "# Validate transformations\n",
        "print(df[['date', 'sale_month', 'house_age', 'is_renovated', 'price_log', 'price_per_sqft', 'age_group']].head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Data Type Optimization**\n",
        "\n",
        "Ensure categorical variables like `zipcode` and `waterfront` are stored correctly to prevent statistical functions from treating them as continuous numbers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 21596 entries, 0 to 21595\n",
            "Data columns (total 31 columns):\n",
            " #   Column              Non-Null Count  Dtype         \n",
            "---  ------              --------------  -----         \n",
            " 0   id                  21596 non-null  int64         \n",
            " 1   date                21596 non-null  datetime64[ns]\n",
            " 2   price               21596 non-null  float64       \n",
            " 3   bedrooms            21596 non-null  int64         \n",
            " 4   bathrooms           21596 non-null  float64       \n",
            " 5   sqft_living         21596 non-null  int64         \n",
            " 6   sqft_lot            21596 non-null  int64         \n",
            " 7   floors              21596 non-null  float64       \n",
            " 8   waterfront          21596 non-null  category      \n",
            " 9   view                21596 non-null  category      \n",
            " 10  condition           21596 non-null  category      \n",
            " 11  grade               21596 non-null  category      \n",
            " 12  sqft_above          21596 non-null  int64         \n",
            " 13  sqft_basement       21596 non-null  int64         \n",
            " 14  yr_built            21596 non-null  int64         \n",
            " 15  yr_renovated        21596 non-null  int64         \n",
            " 16  zipcode             21596 non-null  category      \n",
            " 17  lat                 21596 non-null  float64       \n",
            " 18  long                21596 non-null  float64       \n",
            " 19  sqft_living15       21596 non-null  int64         \n",
            " 20  sqft_lot15          21596 non-null  int64         \n",
            " 21  sale_year           21596 non-null  int32         \n",
            " 22  sale_month          21596 non-null  int32         \n",
            " 23  sale_quarter        21596 non-null  int32         \n",
            " 24  sale_month_name     21596 non-null  object        \n",
            " 25  house_age           21596 non-null  int64         \n",
            " 26  is_renovated        21596 non-null  category      \n",
            " 27  years_since_update  21596 non-null  int64         \n",
            " 28  price_log           21596 non-null  float64       \n",
            " 29  age_group           21596 non-null  category      \n",
            " 30  price_per_sqft      21596 non-null  float64       \n",
            "dtypes: category(7), datetime64[ns](1), float64(7), int32(3), int64(12), object(1)\n",
            "memory usage: 3.9+ MB\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "# Optimize Data Types\n",
        "categorical_cols = ['waterfront', 'view', 'condition', 'grade', 'zipcode', 'is_renovated', 'age_group']\n",
        "for col in categorical_cols:\n",
        "    df[col] = df[col].astype('category')\n",
        "\n",
        "print(df.info())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Load Data Set\n",
        "The dataset is saved as `final_house_data.csv`, ready for Buyer/Seller analysis."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== LOADING DATA ===\n",
            "Data saved to ..\\data\\processed\\final_house_data.csv\n"
          ]
        }
      ],
      "source": [
        "print(\"=== LOADING DATA ===\")\n",
        "\n",
        "try:\n",
        "  # Data directory paths\n",
        "  data_path = os.path.join(\"..\",\"data\",\"processed\")\n",
        "  # Load cleaned dataset\n",
        "  df.to_csv(os.path.join(data_path, \"final_house_data.csv\"), index=False)\n",
        "except Exception as e:\n",
        "  print(e)\n",
        "\n",
        "print(f\"Data saved to {os.path.join(data_path,'final_house_data.csv')}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Conclusions and Next Steps\n",
        "\n",
        "- Successfully transformed the data to use for analayis and predictions.\n",
        "- Trabnsfomed data set is loaded to 'final_house_data.csv'"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Data Practitioner Jupyter Notebook.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": ".venv (3.12.8)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.8"
    },
    "orig_nbformat": 2
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
